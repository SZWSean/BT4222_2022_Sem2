{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zx6EsaGeVLGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e391e74f-a89c-4191-c55b-ee7f3dd421d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os, glob\n",
        "import re\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/4222_tesla/scrape')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_dict = {'tm3':['#model3', 'model 3', 'tesla model 3'], \n",
        "                'tmx':['#modelx', 'model x', 'tesla model x'],\n",
        "                'tmy':['#modely', 'model y', 'tesla model y'],\n",
        "                'tms':['#models', 'model s', 'tesla model s']}\n",
        "\n",
        "all_files = glob.glob(os.path.join(os.getcwd(), 't*.csv'))\n",
        "all_files = [filename.split('/')[-1] for filename in all_files]\n",
        "all_files"
      ],
      "metadata": {
        "id": "P9VHBmUJbzv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff618c6b-4fc5-476f-afaf-531d3d4c8a49"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tm3_jan_apr.csv', 'tmx_jan_apr.csv', 'tmy_jan_apr.csv', 'tms_jan_apr.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Drop unnecessary columns\n",
        "def get_req_col(df_in):\n",
        "    return df_in.iloc[:,[3,4,7,10,15,16,17]]\n",
        "#df2 = df2.to_csv(f\"dropped_Tesla_contents.csv\", index=False) "
      ],
      "metadata": {
        "id": "_epdlLBJbz3v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Clean tweets and drop duplicates (added replace '  ' with ' ')\n",
        "def clean_df(df_in):\n",
        "    df_out = df_in.copy()\n",
        "    df_out['tweet'] = df_out['tweet'].str.replace(\"\\$[^\\s]+\", '').str.replace(\"'\", '').str.replace(\"@[^\\s]+\", '').str.replace(\"#[^\\s]+\", '').str.replace(\"https[^\\s]+\", '').str.replace(\"[^\\x00-\\x7F]+\", '').str.replace('[^\\w\\s]', ' ').str.replace(\" \\d+\", \" \").str.replace(' +', ' ').str.strip()\n",
        "    df_out.drop_duplicates(subset = ['tweet'])\n",
        "    return df_out"
      ],
      "metadata": {
        "id": "B8cSv13ZccJE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Drop rows where tweet does not contain keywords (works better after fixing double spacing)\n",
        "#    df_in = pd.read_csv(df_path)\n",
        "def drop_rows(df_in, keywords):\n",
        "    to_drop = []\n",
        "    for row_index, row in df_in.iterrows():\n",
        "        if keywords[0] not in row['tweet'].lower() and keywords[1] not in row['tweet'].lower() and keywords[2] not in row['tweet'].lower():\n",
        "            to_drop.append(row_index)\n",
        "    df_out = df_in.drop(to_drop)\n",
        "    return df_out"
      ],
      "metadata": {
        "id": "AF_tWaecchQr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MVFfFsBIgDPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in all_files:\n",
        "    product = filename.split('_')[0]\n",
        "    keywords = keyword_dict[product]\n",
        "    df = pd.read_csv(filename)\n",
        "    print('Now processing:', product)\n",
        "    print('Keywords:', keywords)\n",
        "    print('Start len:', len(df))\n",
        "    # Keep required columns\n",
        "    df_req_col = get_req_col(df)\n",
        "    # Clean text in tweets\n",
        "    df_req_col_clean = clean_df(df_req_col)\n",
        "    # Drop tweets which do not contain keywords (Scraped cos keywords found in username etc.)\n",
        "    df_req_col_clean_dropped = drop_rows(df_req_col_clean, keywords)\n",
        "    print('End len:', len(df_req_col_clean_dropped))\n",
        "    # Save as tm3.csv, etc.\n",
        "    save_path = f'/drive/My Drive/folder_name/processed_{product}.csv'\n",
        "    df_req_col_clean_dropped.to_csv(f'processed_{product}.csv', index=False) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrQfgB_kccfA",
        "outputId": "7f5dc5c0-69cd-4dab-8e35-f5fb3082d8f0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now processing: tm3\n",
            "Keywords: ['#model3', 'model 3', 'tesla model 3']\n",
            "Start len: 5721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "End len: 5056\n",
            "Now processing: tmx\n",
            "Keywords: ['#modelx', 'model x', 'tesla model x']\n",
            "Start len: 2778\n",
            "End len: 2478\n",
            "Now processing: tmy\n",
            "Keywords: ['#modely', 'model y', 'tesla model y']\n",
            "Start len: 3527\n",
            "End len: 2888\n",
            "Now processing: tms\n",
            "Keywords: ['#models', 'model s', 'tesla model s']\n",
            "Start len: 910\n",
            "End len: 512\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "name": "dropNclean.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}